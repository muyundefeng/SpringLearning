crawler.retry.times = 30
crawler.interval = 6

# the path of data has been crawled
crawler.data.path = /home/lisheng/data/

# the path of file saving the number of process
crawler.process.path=/home/lisheng/data/ProcessNumber.txt

# crawler.monitor.heartbeats.ip_port is the ip and port to send heartbeat package
# crawler.process.path is the file which keeps the crawling number.
# /home/searcher/server/webapps/ProcessNumber.txt			---server
# /home/crawler/data/
# /home/searcher/server/logs/								---server
# /home/searcher/server/log/adsafdfa
# /home/suifeng/data/										---suifeng

#use proxy for crawler(0:enable 1:disable)
crawler.proxy.enable = 0

# the proxy of crawler
crawler.proxy.host_port =10.108.112.91:808
crawler.proxy.host_port_weight = 1,1,6
# proxy2.asec.buptnsrc.com:8001,proxy.asec.buptnsrc.com:8001,proxy1.asec.buptnsrc.com:8001,

# the host and port to send heartbeats
crawler.monitor.heartbeats.ip_port = test.asec.buptnsrc.com:8000
crawler.monitor.heartbeats.agentId = DMT

# the port to send data which have been crawled
crawler.sendData.port = 8000